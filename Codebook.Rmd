---
title: "Codebook:"
output: html_document
---
###Human Activity Recognition Using Smartphones Dataset (version 1.0)


####Data record 

The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities wearing a smartphone (Samsung Galaxy S II) on the waist:

* WALKING 
* WALKING_UPSTAIRS 
* WALKING_DOWNSTAIRS 
* SITTING 
* STANDING 
* LAYING 

The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data. 

The sensor acceleration signal, which has gravitational and body motion components, was separated into body acceleration and gravity. From each window, a vector of features was obtained by calculating variables from the time and frequency domain. 

Data file list:

* features.txt: List of all features.
* features_info.txt: Shows information about the variables used on the feature vector.
* activity_labels.txt: Links the class labels with their activity name.
* train/X_train.txt: Training set.
* train/y_train.txt: Training labels.
* test/X_test.txt: Test set.
* test/y_test.txt: Test labels.
 
 
#### Variable info 

The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). 

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions. The labels are:

* timedomain.body.acc.mean/std.x/y/z
* timedomain.gravity.acc.mean/std.x/y/z
* timedomain.body.acc.jerk.mean/std.x/y/z
* timedomain.body.gyro.mean/std.x/y/z
* timedomain.body.gyro.jerk.mean/std.x/y/z
* timedomain.body.acc.mag.mean/std
* timedomain.gravity.acc.mag.mean/std
* timedomain.body.acc.jerk.mag.mean/std
* timedomain.body.gyro.mag.mean/std
* timedomain.body.gyro.jerk.mag.mean/std
* frequencydomain.body.acc.mean/std.x/y/z
* frequencydomain.body.acc.jerk.mean/std.x/y/z
* frequencydomain.body.gyro.mean.mean/std.x/y/z
* frequencydomain.body.acc.mag.mean/std
* frequencydomain.body.body.acc.jerk.mag.mean/std
* frequencydomain.body.body.gyro.mag.mean/std
* frequencydomain.body.body.gyro.jerk.mag.mean/std

The set of variables that were estimated from these signals are:

* mean: Mean value
* std: Standard deviation
 
 
####Transformation

The resulting tidy data consists of 30 study subjects and 6 activity levels and mean values of 66 measurements each, ie. 180 rows, 68 columns. 


####Notes 

- Features are normalized and bounded within [-1,1].
- Each feature vector is a row on the text file.
